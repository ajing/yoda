{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "> yoda wants to simplify the way to run jobs on Google AI platform and organize your model process in a config file.\n",
    "\n",
    "In this session, we will go through a few examples to see how yoda works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import pickle\n",
    "import typing\n",
    "from functools import lru_cache\n",
    "from io import TextIOWrapper\n",
    "\n",
    "import blocks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import yaml\n",
    "from blocks.filesystem import GCSFileSystem\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Data:\n",
    "    def __init__(self, input_path: str, output_path: str, features: str, label: str, **kwargs):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.feature_list = features.split(\",\")\n",
    "        self.label = label\n",
    "        self.eval_path = kwargs.get(\"eval_path\", None)\n",
    "        self.score_path = kwargs.get(\"score_path\", None)\n",
    "        self.is_gcp = input_path.startswith(\"gs://\")\n",
    "\n",
    "    @property\n",
    "    @lru_cache(1)\n",
    "    def df(self):\n",
    "        return blocks.assemble(self.input_path)\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.df[self.feature_list]\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self.df[self.label]\n",
    "\n",
    "    @property\n",
    "    @lru_cache(1)\n",
    "    def eval_df(self):\n",
    "        if not self.eval_path:\n",
    "            raise Exception(\"Please specify the eval_path\")\n",
    "        return blocks.assemble(self.eval_path)\n",
    "\n",
    "    @property\n",
    "    def eval_X(self):\n",
    "        return self.eval_df[self.feature_list]\n",
    "\n",
    "    @property\n",
    "    def eval_y(self):\n",
    "        return self.eval_df[self.label]\n",
    "\n",
    "    @property\n",
    "    @lru_cache(1)\n",
    "    def score_df(self):\n",
    "        if not self.score_path:\n",
    "            raise Exception(\"Please specify the score_path\")\n",
    "        return blocks.assemble(self.score_path)\n",
    "\n",
    "    @property\n",
    "    def score_X(self):\n",
    "        return self.score_df[self.feature_list]\n",
    "\n",
    "    def open(self, filename) -> TextIOWrapper:\n",
    "        full_path = os.path.join(self.output_path, filename)\n",
    "        opener = GCSFileSystem().open if self.is_gcp else open\n",
    "        with opener(full_path) as fobj:\n",
    "            yield fobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _import_from_string(classname: str):\n",
    "    components = classname.split('.')\n",
    "    mod = __import__(components[0])\n",
    "    for comp in components[1:]:\n",
    "        mod = getattr(mod, comp)\n",
    "    return mod\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, estimator: str, params: dict):\n",
    "        self.estimator = _import_from_string(estimator)(**params)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
    "        self.estimator.fit(X, y, **kwargs)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame, **kwargs):\n",
    "        self.estimator.predict(X, **kwargs)\n",
    "\n",
    "    def save(self, fobj):\n",
    "        pickle.dump(self.estimator, fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _eval(estimator: sklearn.base.BaseEstimator = None,\n",
    "          data: Data = None,\n",
    "          cv=None,\n",
    "          metrics: str = None) -> dict:\n",
    "    if data.eval_path is not None and cv is not None:\n",
    "        raise Exception(\n",
    "            \"eval_path: (%s) and cv: (%s) cannot co-exist\" % (data.eval_path, cv))\n",
    "\n",
    "    eval_res = dict()\n",
    "    for metric in metrics:\n",
    "        if data.eval_path is not None:\n",
    "            estimator.fit(data.X, data.y)\n",
    "            scorer = sklearn.metrics.SCORERS[metric]\n",
    "            avg, sd = scorer(estimator, data.eval_X, data.eval_y), 0\n",
    "        if cv is not None:\n",
    "            scores = cross_val_score(\n",
    "                estimator, data.X, data.y, cv=cv, scoring=metric)\n",
    "            avg, sd = np.mean(scores), np.std(scores)\n",
    "\n",
    "        eval_res[metric] = {\"sd\": sd, \"avg\": avg}\n",
    "    return eval_res\n",
    "\n",
    "\n",
    "def run_eval(conf_dict: dict, data: Data, estimator, output_dir: str = \"eval.pkl\"):\n",
    "    eval_path = data.eval_path\n",
    "    metrics_str = conf_dict[\"eval\"].get(\"metrics\")\n",
    "    cv = conf_dict[\"eval\"].get(\"cv\")\n",
    "    metrics = metrics_str.split(\",\") if metrics_str else None\n",
    "    result = _eval(estimator, data, cv, metrics)\n",
    "    conf_cp = dict(conf_dict)\n",
    "    conf_cp[\"eval_result\"] = result\n",
    "    # TODO: consider to create an class here and do\n",
    "    # evaluate.save()\n",
    "    if output_dir:\n",
    "        pickle.dump(conf_cp, data.open(output_dir))\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_on_dict(conf_dict: dict):\n",
    "    data = Data(**conf_dict['data'])\n",
    "    train = Train(**conf_dict['train'])\n",
    "    if \"eval\" in conf_dict or data.eval_path:\n",
    "        run_eval(conf_dict, data, train.estimator)\n",
    "    else:\n",
    "        train.fit(data.X, data.y)\n",
    "        train.save(data.open(\"model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FormatTag(yaml.YAMLObject):\n",
    "    \"\"\"\n",
    "    This tag supporting: NOW, EPOCH, and anything from environment variable\n",
    "    \"\"\"\n",
    "    yaml_tag = u'!format'\n",
    "    yaml_loader = yaml.SafeLoader\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, loader, node):\n",
    "        import calendar\n",
    "        import time\n",
    "\n",
    "        fillin_dict = dict(os.environ)\n",
    "        update_dict = {\n",
    "            \"NOW\": time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "            \"EPOCH\": calendar.timegm(time.gmtime()),\n",
    "        }\n",
    "        fillin_dict.update(update_dict)\n",
    "        values = loader.construct_scalar(node)\n",
    "        return values.format(**fillin_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a config file `config1.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: \n",
      "  input_path: \"../data/iris_data.csv\"\n",
      "  eval_path: \"../data/iris_data.csv\"\n",
      "  output_path: \"../output/\"\n",
      "  features: \"sepal_length,sepal_width,petal_length\"\n",
      "  label: species\n",
      "train:\n",
      "  estimator: xgboost.XGBClassifier\n",
      "  params:\n",
      "    max_depth: 4\n",
      "    num_estimator: 50\n",
      "eval:\n",
      "  metrics: \"accuracy,f1_macro\"\n"
     ]
    }
   ],
   "source": [
    "config1 = '../data/configs/config1.yaml'\n",
    "with open(config1) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this config file locally by \n",
    "\n",
    "```{shell}\n",
    "yoda run config1.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is how yoda process the config file, you can safely ignore this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file\n",
    "conf_dict = yaml.load(open(config1), Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'input_path': '../data/iris_data.csv',\n",
       "  'eval_path': '../data/iris_data.csv',\n",
       "  'output_path': '../output/',\n",
       "  'features': 'sepal_length,sepal_width,petal_length',\n",
       "  'label': 'species'},\n",
       " 'train': {'estimator': 'xgboost.XGBClassifier',\n",
       "  'params': {'max_depth': 4, 'num_estimator': 50}},\n",
       " 'eval': {'metrics': 'accuracy,f1_macro'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the ***Data*** session, yoda loads the config file and read the data from input_path. The data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(**conf_dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length\n",
       "0           0.0          1.0           2.0\n",
       "1           5.1          3.5           1.4\n",
       "2           4.9          3.0           1.4\n",
       "3           4.7          3.2           1.3\n",
       "4           4.6          3.1           1.5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    51\n",
       "2    50\n",
       "1    50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, it will generate an object for the ***Train*** session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Train(**conf_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fit(data.X, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'sd': 0, 'avg': 1.0}, 'f1_macro': {'sd': 0, 'avg': 1.0}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_eval(conf_dict, data, train.estimator, output_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dict[\"eval\"][\"cv\"] = 5\n",
    "data.eval_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'sd': 0.0574503560948385, 'avg': 0.9402150537634408},\n",
       " 'f1_macro': {'sd': 0.05748872061476293, 'avg': 0.9398830409356724}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_eval(conf_dict, data, train.estimator, output_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on GCP AI platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run on AI platform, we need to create an image that have all depedencies installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{shell}\n",
    "export PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")\n",
    "export IMAGE_REPO_NAME=yoda\n",
    "export IMAGE_TAG=basic\n",
    "export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "docker build -f ../docker/Dockerfile.basic -t $IMAGE_URI ./\n",
    "docker push $IMAGE_URI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config for GCP looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: \n",
      "  input_path: !format \"gs://{BUCKET}/{USER}/test/iris_data.csv\"\n",
      "  eval_path: !format \"gs://{BUCKET}/{USER}/test/iris_data.csv\"\n",
      "  output_path: !format \"gs://{BUCKET}/{USER}/test/output/\"\n",
      "  features: \"sepal_length,sepal_width,petal_length\"\n",
      "  label: species\n",
      "train:\n",
      "  estimator: xgboost.XGBClassifier\n",
      "  params:\n",
      "    max_depth: 4\n",
      "    num_estimator: 50\n",
      "eval:\n",
      "  metrics: \"accuracy,f1_macro\"\n"
     ]
    }
   ],
   "source": [
    "config2 = '../data/configs/config2.yaml'\n",
    "with open(config2) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"BUCKET\"] = \"testjobsubmit\"\n",
    "conf_dict2 = yaml.safe_load(open(config2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'input_path': 'gs://testjobsubmit/j0l04cl/test/iris_data.csv',\n",
       "  'eval_path': 'gs://testjobsubmit/j0l04cl/test/iris_data.csv',\n",
       "  'output_path': 'gs://testjobsubmit/j0l04cl/test/output/',\n",
       "  'features': 'sepal_length,sepal_width,petal_length',\n",
       "  'label': 'species'},\n",
       " 'train': {'estimator': 'xgboost.XGBClassifier',\n",
       "  'params': {'max_depth': 4, 'num_estimator': 50}},\n",
       " 'eval': {'metrics': 'accuracy,f1_macro'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yoda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0cf725b51ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myoda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yoda'"
     ]
    }
   ],
   "source": [
    "import yoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yoda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a35d887c3441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myoda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_yoda_on_gcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrun_yoda_on_gcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_dict2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yoda'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from yoda.runner import run_yoda_on_gcp\n",
    "\n",
    "run_yoda_on_gcp(conf_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_run.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('yoda': conda)",
   "language": "python",
   "name": "python37664bityodaconda1761fd571982482b8d09f32c72d421ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
